\chapter{Experimental Evaluation}
\label{ch:experiments}

In this chapter we illustrate experimental studies that we have performed for the techniques described in \mychapter\ref{ch:profiling,ch:continuous}. Our techniques have been implemented in production systems and typically evaluated against industry-strength benchmarks. For performance metrics, reported figures have been obtained by performing multiple runs in a Linux system with negligible background activity, and we also show confidence intervals stated at $95\%$ confidence level where possible.

In the first part of the chapter, we evaluate our space-efficient inter-procedural technique for context-sensitive profiling. In our analysis, we take into account a large collection of prominent interactive Linux applications and benchmarks from popular suites. Results collected for a number of accuracy and space usage metrics reinforce the theoretical prediction that the HCCT achieves a similar precision as the CCT in a space that is several orders of magnitude smaller, and roughly proportional to the number of hot contexts. Our implementation is casted in a full-fledged infrastructure that we developed for profiling multi-threaded Linux C/C++ applications, and ships as a plugin for the GNU C/C++ \gcc\ compiler. We also discuss how we integrated our technique with static bursting, resulting in faster running times without substantially affecting accuracy: we incur a slowdown competitive with the \gprof\ call-graph profiler, while collecting finer-grained program profiles. 

In the second part, we discuss an implementation in the Jikes RVM of our intra-procedural technique for multi-iteration path profiling. We present a broad experimental study on a large suite of prominent Java benchmarks, showing that our profiler can collect profiles that would have been too costly to gather using previous multi-iteration techniques. The key to the efficiency of our approach is to replace costly hash table accesses, which are  required by the Ball-Larus algorithm to maintain path counters for larger programs, with substantially faster operations on trees. We then study structural properties of path profiles that span multiple iterations for several representative benchmarks, and discuss memory footprints of the \ksf\ and \kipf\ data structures for increasing values of $k$.

Finally, we present an extensive experimental evaluation of our OSR techniques for continuous program optimization. We analyze the performance of \osrkit\ in the \tinyvm\ proof-of-concept virtual machine that we developed in LLVM. Our goal is to address a number of typical concerns of VM builders, measuring, e.g., the impact of having an OSR point in a hot code portion, and the actual cost of performing an OSR transition. We also measure the time required by \osrkit\ to insert an OSR point and to create a stub or a continuation function. We then \missing

\section{HCCT Construction and Accuracy}

\section{{\em k-}iteration Path Profiling}

\section{On-Stack Replacement}